% !TeX spellcheck = en_US
\chapter{Introduction}
Ensemble methods are composed by a set of base classifiers, whose results are combined in order to improve the accuracy of the single classifier. In this project we've used \textit{AdaBoost}, a boosting meta-algorithm which belongs to the ensemble learning family to classify forests given a set of features such as elevation, aspect, soil types and many others. The base classifiers used by AdaBoost are the \textit{decision stumps}. A decision stump is a decision tree composed by an internal node immediately connected to the terminal nodes. In this project, the decision stumps are composed by the root and two leaves and will predict in the set ${-1, +1}$. After, we've implemented the \textit{Bagging Algorithm} to perform the same classification using \textit{one-vs-all} to perform multiclass classification. Finally we've used the external \textit{cross validation} to evaluate and compare the accuracy of both AdaBoost and the Bagging Algorithm.