% !TeX spellcheck = en_US

\chapter{The Bagging Algorithm}

\textit{Bagging} is short for \textit{Bootstrap Aggregating}, a machine learning meta-algorithm used in statistical classification and regression. Like AdaBoost, it works with base classifiers.\\
Bagging samples $m$ subsets $S^{\prime}$ of the same size from a training set $S$ uniformly with replacement. Each $S^{\prime}$ is given as input to the chosen base classifiers and their output is combined.
\begin{algorithm}[htpb]
	\caption{}
	\label{alg:bagging}
	\begin{algorithmic}[1]
		\Procedure{Bagging}{$L(\cdot), S, T$}
		\State $A \gets \varnothing$
		\State $w \gets \varnothing$
		\For{$i=1 \textbf{ to } n$}
		\State $A \gets A \cup \texttt{Bootstrap}(L,S)$
		\EndFor
		\Return mean($A$)
		\EndProcedure
		\Procedure{Bootstrap}{$L(\cdot), S$}
		\State $S^{\prime} \gets \varnothing$
		\For{$i=1\textbf{ to }|S|$}
		\State be $x_{i}$ a random sample drawn uniformly from $S$
		\State increment by $1$ the weight $w_{i}$ associated to $x_{i}$
		\State $S^{\prime} \gets S^{\prime} \cup x$
		\EndFor
		\\
		\Return $L(S^{\prime}, w)$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}
In this project, the Bagging algorithm combines the results of many decision stumps over the training set by averaging them.
