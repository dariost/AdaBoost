% !TeX spellcheck = en_US

\chapter{The Bagging Algorithm}

\textit{Bagging} is the short name for \textit{bootstrap aggregating} and it is an ensemble algorithm for machine learning. This algorithm combine the strength of the \textit{bootstrap method} to improve the accuracy and reduce the variance. The bootstrap is a powerful statistical method for estimating a quantity over a data-set. For example, given a set $\mathbb{X}$ of $n$ samples, we would like to estimate its mean:
\begin{align*}
	\bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_{i}
\end{align*}
We know that $\bar{x}$ has some error in it. To improve this estimation, we can do as follows:
\begin{itemize}
	\item create $k$ random sub-samples of $\mathbb{X}$ with repetitions of a fixed size $t$
	\item for each of the $k$ sub-samples, calculate their mean
	\item average all the means and use that data as the estimation $\bar{x}$
\end{itemize}
\begin{algorithm}[htpb]
	\caption{}
	\label{alg:bagging}
	\begin{algorithmic}[1]
		\Procedure{Bagging}{$L(\cdot), S, T$}
		\State $A \gets \varnothing$
		\State $w \gets \varnothing$
		\For{$i=1 \textbf{ to } n$}
		\State $A \gets A \cup \texttt{Bootstrap}(L,S)$
		\EndFor
		\Return mean($A$)
		\EndProcedure
		\Procedure{Bootstrap}{$L(\cdot), S$}
		\State $S^{\prime} \gets \varnothing$
		\For{$i=1\textbf{ to }|S|$}
		\State be $x_{i}$ a random sample drawn uniformly from $S$
		\State increment by $1$ the weight $w_{i}$ associated to $x_{i}$
		\State $S^{\prime} \gets S^{\prime} \cup x$
		\EndFor
		\\
		\Return $L(S^{\prime}, w)$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}
In this project, the Bagging algorithm combines the results of many decision stumps over the training set by averaging them.
